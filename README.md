# Music Player with Machine Learning
This is a project using machine learning for detecting emotions based on the expression of the users. 

The interface comprises HTML, CSS, JS, and the main code in Python.

This code is developed in Windows, with eel, OpenCV, and Python.

# Requirements:
  Python version: 3.7 or above
  Modules: glob, os, NumPy, random, argparse, time, Eel
  OpenCV( Full OpenCV module  Fisherface module is a must)
  Chrome browser is needed (eel library is specifically designed for chrome)

# code:
  All files should be in the same folder.
# Run "capture.py" in your editor or  terminal

  Python terminal Navigate to a chrome window open with an interface of the music player. By Selecting emotion mode webcam will capture the image. Based on the image results, emotion is detected, and emoji will be displayed on the monitor.

  When emotion is detected, you can see the name of the emotion in the terminal open.

  Refer to READIT.odt for more info.
  
  # Model Looks Like
  <h1 align="center">Hey there <img src="https://github.com/Chowdary-07/Emotion_Based_Music_Player/blob/main/image9.png"</h1>
  
